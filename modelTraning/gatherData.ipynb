{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "parent_dir= './datas/'\n",
    "sub_dir = ['00Sitting','01Waving','02Walking','03Jumping','04Running']\n",
    "LABEL = {\n",
    "    0: 'Sitting',\n",
    "    1: 'Stretching',\n",
    "    2: 'Walking',\n",
    "    3: 'Jumping',\n",
    "    4: 'Running'\n",
    "}\n",
    "window_size = 25\n",
    "shift_amount = 5\n",
    "augmentation = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# segment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(data,size):\n",
    "    start = 0\n",
    "    while start< len(data):\n",
    "        yield int(start), int(start + size)\n",
    "        start+= (size/2)\n",
    "        # start += size\n",
    "\n",
    "def data_shifting(data,shift_amount):\n",
    "    # amout1 = np.random.randint(-shift_amount,shift_amount) or np.random.randint(-shift_amount,shift_amount)\n",
    "    # amout2 = np.random.randint(-shift_amount,shift_amount//2) or np.random.randint(-shift_amount,shift_amount//2)\n",
    "    # while amout1 == amout2:\n",
    "    #     amout2 = np.random.randint(-shift_amount,shift_amount//2) or np.random.randint(-shift_amount,shift_amount//2)\n",
    "    # return np.roll(data, amout1),np.roll(data, amout2)\n",
    "        \n",
    "    shift_amount = np.random.randint(-shift_amount,shift_amount) or np.random.randint(-shift_amount,shift_amount)\n",
    "    shifted_data = np.roll(data, shift_amount)\n",
    "    return shifted_data\n",
    "\n",
    "\n",
    "def segment_signal(file_path,window_size,augmentation=False):\n",
    "    \n",
    "    data = np.genfromtxt(file_path, delimiter=',', dtype=\"int\", encoding=None)\n",
    "    \n",
    "    segments = np.empty((0, window_size),dtype=float) \n",
    "    labels = np.empty(0,dtype=int)\n",
    "    \n",
    "    for (start, end) in sliding_window(range(len(data)), window_size):\n",
    "        try:\n",
    "            v = np.array(data[start:end,3])\n",
    "            label = np.array(data[start:end,0])\n",
    "            if augmentation:\n",
    "                v_aug1= data_shifting(v,shift_amount)\n",
    "                # v_aug2 = data_shifting(v,shift_amount)\n",
    "            if len(v) == window_size:\n",
    "                segments = np.vstack([segments, v]) if not augmentation else np.vstack([segments, v,v_aug1])\n",
    "                labels = np.append(labels,label[0]) if not augmentation else np.append(labels,[label[0],label[0]])\n",
    "        except Exception as e:\n",
    "            print(f'error: {e}')\n",
    "            print(f'files{file_path}') \n",
    "            exit()  \n",
    "            \n",
    "    print(f'file_path:{file_path}')\n",
    "    print(f\"segments.shape{segments.shape}\")\n",
    "    print(f\"labels.shape{labels.shape}\")\n",
    "    return segments, labels\n",
    "\n",
    "def traverse_folder(folder_path):\n",
    "    for file in os.listdir(folder_path):\n",
    "        content_path = os.path.join(folder_path, file)\n",
    "        if os.path.isfile(content_path):\n",
    "            segment,label = segment_signal(content_path,window_size,augmentation=augmentation)\n",
    "            yield segment,label\n",
    "        else:\n",
    "            print(f'not file: {content_path}')\n",
    "            \n",
    "def combine_segments(prefix):\n",
    "    # train data\n",
    "    segments = np.empty((0, window_size),dtype=int)  \n",
    "    labels = np.empty(0,dtype=int)  \n",
    "\n",
    "    for segment, label in traverse_folder(prefix):\n",
    "        segments = np.concatenate((segments, segment), axis=0)\n",
    "        labels = np.concatenate((labels, label), axis=0)\n",
    "    \n",
    "    \n",
    "    print(f'==SummarizeTrain=={LABEL[labels[0]]}====')\n",
    "    print(f\"segments.shape{segments.shape}\")\n",
    "    print(f\"labels.shape{labels.shape}\")\n",
    "    return segments, labels\n",
    "\n",
    "\n",
    "def load_test_data(sub_dir):\n",
    "    prefix =   parent_dir + 'testData/'+ sub_dir + '/'\n",
    "    segments = np.empty((0, window_size),dtype=int)  \n",
    "    labels = np.empty(0,dtype=int)  \n",
    "\n",
    "    for segment, label in traverse_folder(prefix):\n",
    "        segments = np.concatenate((segments, segment), axis=0)\n",
    "        labels = np.concatenate((labels, label), axis=0)\n",
    "        traverse_plot(prefix)\n",
    "        \n",
    "    print(f'==SummarizeTest=={LABEL[labels[0]]}====')\n",
    "    print(f\"segments.shape{segments.shape}\")\n",
    "    print(f\"labels.shape{labels.shape}\")\n",
    "    return segments, labels\n",
    "\n",
    "# prefix = parent_dir + sub_dir[0] + '/'\n",
    "# segments, labels = combine_segments(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the velocity vs time\n",
    "import matplotlib.pyplot as plt\n",
    "size = 1000\n",
    "def traverse_plot(folder_path):\n",
    "    for file in os.listdir(folder_path):\n",
    "        content_path = os.path.join(folder_path, file)\n",
    "        if os.path.isfile(content_path):\n",
    "            print(f'plot graph for file: {content_path}')\n",
    "            activ_data = get_data(content_path)\n",
    "            plot_velocity(activ_data)\n",
    "            plot_coordinate(activ_data)\n",
    "        else:\n",
    "            print(f'not file: {content_path}')\n",
    "            \n",
    "def get_data(file_path):\n",
    "    data = np.genfromtxt(file_path, delimiter=',', dtype=\"int\", encoding=None)\n",
    "    \n",
    "    t = np.arange(0, len(data) * 0.1, 0.1)\n",
    "    label = np.array(data[:,0])\n",
    "    v = np.array(data[:, 3] / 100)\n",
    "    x = np.array(data[:, 1] / 1000)\n",
    "    y = np.array(data[:, 2] / 1000)\n",
    "\n",
    "    activ_data = np.vstack((label, t, x, y, v)).T\n",
    "    return activ_data\n",
    "\n",
    "def plot_coordinate(activ_data,size=3000):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    x = activ_data[:, 2]\n",
    "    y = activ_data[:, 3]\n",
    "    v = activ_data[:, 4]\n",
    "    label = LABEL[activ_data[:, 0][0]]\n",
    "    plt.scatter(x, y, c=v, cmap='viridis', marker='o', label='Position',s=5)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('Y')\n",
    "    plt.colorbar(label='velocity')\n",
    "    plt.title(label=label)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_velocity(activ_data,size=3000):\n",
    "    fig, ax = plt.subplots(figsize=(15, 4))\n",
    "\n",
    "    ax.plot(activ_data[:, 1], activ_data[:, 4])\n",
    "    ax.set_xlabel('t(s)')\n",
    "    ax.set_ylabel('v(m/s)')\n",
    "    ax.set_title(LABEL[activ_data[:, 0][0]] + ' velocity vs time', fontsize=16)\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merging all activities into one npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(datas,train_ratio=0.8):\n",
    "    segments,labels = datas\n",
    "    total_samples = len(segments)\n",
    "    # indices = np.arange(total_samples)\n",
    "    # np.random.shuffle(indices)\n",
    "    \n",
    "    # splitting in training and testing data\n",
    "    trainSplit = np.random.rand(total_samples) < train_ratio\n",
    "    \n",
    "    train_segments = segments[trainSplit]\n",
    "    test_segments = segments[~trainSplit]\n",
    "    # train_segments = np.nan_to_num(train_segments)\n",
    "    # test_segments = np.nan_to_num(test_segments)\n",
    "    train_labels = labels[trainSplit]\n",
    "    test_labels = labels[~trainSplit]\n",
    "    print(\"After splitting:\")\n",
    "    print(f'train:{train_segments.shape},test:{test_segments.shape}')\n",
    "    return train_segments,train_labels,test_segments, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====loading Testdata=====\n",
      "file_path:./datas2/00Sitting/Sitting 2023-12-13 17229.txt\n",
      "segments.shape(1208, 25)\n",
      "labels.shape(1208,)\n",
      "file_path:./datas2/00Sitting/Sitting 2023-12-13 173537.txt\n",
      "segments.shape(1026, 25)\n",
      "labels.shape(1026,)\n",
      "file_path:./datas2/00Sitting/Sitting 2023-12-21 162741.txt\n",
      "segments.shape(650, 25)\n",
      "labels.shape(650,)\n",
      "==SummarizeTrain==Sitting====\n",
      "segments.shape(2884, 25)\n",
      "labels.shape(2884,)\n",
      "After splitting:\n",
      "train:(2342, 25),test:(542, 25)\n",
      "=====loading Testdata=====\n",
      "file_path:./datas2/01Waving/Waving 2023-12-13 20546.txt\n",
      "segments.shape(1120, 25)\n",
      "labels.shape(1120,)\n",
      "file_path:./datas2/01Waving/Waving 2023-12-13 2199.txt\n",
      "segments.shape(1274, 25)\n",
      "labels.shape(1274,)\n",
      "file_path:./datas2/01Waving/Waving 2023-12-21 163641.txt\n",
      "segments.shape(440, 25)\n",
      "labels.shape(440,)\n",
      "==SummarizeTrain==Stretching====\n",
      "segments.shape(2834, 25)\n",
      "labels.shape(2834,)\n",
      "After splitting:\n",
      "train:(2269, 25),test:(565, 25)\n",
      "=====loading Testdata=====\n",
      "file_path:./datas2/02Walking/Walking 2023-12-14 10614.txt\n",
      "segments.shape(1132, 25)\n",
      "labels.shape(1132,)\n",
      "file_path:./datas2/02Walking/Walking 2023-12-14 95354.txt\n",
      "segments.shape(1090, 25)\n",
      "labels.shape(1090,)\n",
      "file_path:./datas2/02Walking/Walking 2023-12-21 223145.txt\n",
      "segments.shape(522, 25)\n",
      "labels.shape(522,)\n",
      "==SummarizeTrain==Walking====\n",
      "segments.shape(2744, 25)\n",
      "labels.shape(2744,)\n",
      "After splitting:\n",
      "train:(2183, 25),test:(561, 25)\n",
      "=====loading Testdata=====\n",
      "file_path:./datas2/03Jumping/Jumping 2023-12-14 101911.txt\n",
      "segments.shape(562, 25)\n",
      "labels.shape(562,)\n",
      "file_path:./datas2/03Jumping/Jumping 2023-12-14 112821.txt\n",
      "segments.shape(562, 25)\n",
      "labels.shape(562,)\n",
      "file_path:./datas2/03Jumping/Jumping 2023-12-14 142648.txt\n",
      "segments.shape(554, 25)\n",
      "labels.shape(554,)\n",
      "file_path:./datas2/03Jumping/Jumping 2023-12-14 142826.txt\n",
      "segments.shape(550, 25)\n",
      "labels.shape(550,)\n",
      "file_path:./datas2/03Jumping/Jumping 2023-12-21 175127.txt\n",
      "segments.shape(440, 25)\n",
      "labels.shape(440,)\n",
      "==SummarizeTrain==Jumping====\n",
      "segments.shape(2668, 25)\n",
      "labels.shape(2668,)\n",
      "After splitting:\n",
      "train:(2144, 25),test:(524, 25)\n",
      "=====loading Testdata=====\n",
      "file_path:./datas2/04Running/Running 2023-12-14 161746.txt\n",
      "segments.shape(1122, 25)\n",
      "labels.shape(1122,)\n",
      "file_path:./datas2/04Running/Running 2023-12-14 195450.txt\n",
      "segments.shape(1090, 25)\n",
      "labels.shape(1090,)\n",
      "file_path:./datas2/04Running/Running 2023-12-21 204539.txt\n",
      "segments.shape(540, 25)\n",
      "labels.shape(540,)\n",
      "==SummarizeTrain==Running====\n",
      "segments.shape(2752, 25)\n",
      "labels.shape(2752,)\n",
      "After splitting:\n",
      "train:(2208, 25),test:(544, 25)\n",
      "=====saving data=====\n",
      "train_segments.shape: (11146, 25)\n",
      "train_labels.shape: (11146,)\n",
      "test_segments.shape: (2736, 25)\n",
      "test_labels.shape: (2736,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = {\n",
    "    'train_segments': np.empty((0, window_size),dtype=int), \n",
    "    'train_labels': np.empty(0, dtype=int), \n",
    "    'test_segments': np.empty((0, window_size),dtype=int), \n",
    "    'test_labels': np.empty(0,dtype=int)\n",
    "}\n",
    "train_ratio = 0.8\n",
    "# shuffle_results = []\n",
    "for IDX in range(5):\n",
    "    prefix = parent_dir + sub_dir[IDX] + '/'\n",
    "    # segments, labels = combine_segments(prefix)\n",
    "    # train_segment, test = combine_segments(prefix)\n",
    "    print(f\"=====loading Testdata=====\")\n",
    "    shuffle_results = split_data(combine_segments(prefix),train_ratio=train_ratio)\n",
    "    # traverse_plot(prefix)\n",
    "    # print(f\"=====loading Traindata=====\")\n",
    "    # test_segments, test_labels = shuffle_data(load_test_data(sub_dir[IDX]))\n",
    "\n",
    "    # shuffle_results.append(shuffle_data(combine_segments(prefix)))\n",
    "    # traverse_plot(prefix)\n",
    "    # shuffle_results.append (shuffle_data(load_test_data(sub_dir[IDX])))\n",
    "\n",
    "    for i, key in enumerate(['train_segments', 'train_labels', 'test_segments', 'test_labels']):\n",
    "        data[key] = np.concatenate([data[key], shuffle_results[i]],axis=0)\n",
    "        # data[key] = np.concatenate([data[key], locals()[key]], axis=0)\n",
    "\n",
    "print(\"=====saving data=====\")\n",
    "for key, value in data.items():\n",
    "    print(f\"{key}.shape: {value.shape}\")\n",
    "    np.save(f\"{key}.npy\", value)\n",
    "\n",
    "t = data['train_segments']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_ba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
